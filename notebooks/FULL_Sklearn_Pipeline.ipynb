{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8de749-5dd9-4cf6-81e7-a9fad907ec49",
   "metadata": {},
   "source": [
    "# Pr√©disez la consommation d'√©nergie des b√¢timents dans la ville de Seattle.\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"https://user.oc-static.com/upload/2024/09/11/17260684381511_Capture%20d%E2%80%99e%CC%81cran%202024-09-11%20a%CC%80%2017.22.25.png\" width=\"200px\">\n",
    "</div>\n",
    "\n",
    "## **Objetif**: Pr√©dire les **√©missions de CO2** et la **consommation totale d‚Äô√©nergie** de **b√¢timents non destin√©s √† l‚Äôhabitation**\n",
    "\n",
    "- Auteur......: **Rafael CEREZO MARTIN**\n",
    "- Date........: **D√©cembre 2025**\n",
    "\n",
    "# <span style=\"color:red\"> üèÜ Mod√©lisation compl√®te via sklearn.pipeline int√©grant le Feature Engineering.</span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70eaf770-2a8f-42ce-ad0c-845de7cbe835",
   "metadata": {},
   "source": [
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5c2ae-b2b5-4cf8-8b6c-96e57e79d371",
   "metadata": {},
   "source": [
    "# ‚¨áÔ∏è IMPORTATION DES LIBRAIRIES (STACK DE SCIENCE DES DONN√âES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae29a79a-01d1-4b1a-941f-a271ed8d6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# MODULES STANDARDS ET BIBLIOTH√àQUES TIERCES\n",
    "# ##############################################################################\n",
    "\n",
    "# Biblioth√®ques de base\n",
    "import os                                     # Gestion du syst√®me de fichiers\n",
    "import joblib                                 # Persistance des objets Python\n",
    "import numpy             as np                # Calcul num√©rique optimis√©\n",
    "import pandas            as pd                # Manipulation de structures data\n",
    "\n",
    "# Transformation et Preprocessing Sklearn\n",
    "from   sklearn.pipeline  import Pipeline      # Encha√Ænement des transformations\n",
    "from   sklearn.compose   import ColumnTransformer # Application par colonnes\n",
    "from   sklearn.impute    import SimpleImputer # Gestion des valeurs manquantes\n",
    "from   sklearn.preprocessing import (\n",
    "    StandardScaler,                           # Normalisation des donn√©es\n",
    "    OneHotEncoder,                            # Encodage cat√©goriel binaire\n",
    "    FunctionTransformer                       # Transformations personnalis√©es\n",
    ")\n",
    "\n",
    "# Mod√®les et √âvaluation\n",
    "from   sklearn.dummy           import DummyRegressor        # Mod√®le de base\n",
    "from   sklearn.ensemble        import RandomForestRegressor # For√™t al√©atoire\n",
    "from   sklearn.linear_model    import LinearRegression      # R√©gression lin√©aire\n",
    "from   sklearn.svm             import SVR                   # Machine √† vecteurs de support\n",
    "\n",
    "from   sklearn.model_selection import (\n",
    "    train_test_split,                         # Division du jeu de donn√©es\n",
    "    cross_validate,                           # Validation crois√©e\n",
    "    KFold                                     # Strat√©gie de d√©coupage CV\n",
    ")\n",
    "from   sklearn.metrics   import (\n",
    "    r2_score,                                 # Coefficient de d√©termination\n",
    "    mean_squared_error                        # Erreur quadratique moyenne\n",
    ")\n",
    "\n",
    "# Encodages avanc√©s\n",
    "from   category_encoders import TargetEncoder # Encodage par la cible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d083f0a-a6b7-413e-9713-15752c83daf9",
   "metadata": {},
   "source": [
    "# ‚úÇÔ∏è Load and Split Dataset pour Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6934713-85a9-49a7-bc77-3ad812dff10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "√âTAPE 4 : EX√âCUTION DU WORKFLOW DE MOD√âLISATION\n",
      "============================================================================\n",
      "‚ö†Ô∏è Nettoyage Target...: 5 lignes supprim√©es\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n============================================================================\")\n",
    "print(\"√âTAPE 4 : EX√âCUTION DU WORKFLOW DE MOD√âLISATION\")\n",
    "print(\"============================================================================\")\n",
    "# Chargement et s√©paration initiale\n",
    "df_raw               = pd.read_csv('2016_Building_Energy_Benchmarking.csv')\n",
    "X_prep, y_prep       = preparation_initiale(df_raw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_prep, y_prep, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9605047-5270-4162-86ad-2a1588849844",
   "metadata": {},
   "source": [
    "# ‚¨áÔ∏è üë§ METHODES POUR LE PRE-PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8b7c2f9-162a-4a27-8fd8-b50111a3a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# √âTAPE 0 : PR√âPARATION INITIALE (NETTOYAGE HORS-PIPELINE)\n",
    "# ##############################################################################\n",
    "\n",
    "def preparation_initiale(df, target='SiteEnergyUse(kBtu)'):\n",
    "    \"\"\"\n",
    "    R√©alise le nettoyage structurel et √©limine les valeurs cibles manquantes.\n",
    "    \"\"\"\n",
    "    df_work          = df.copy()\n",
    "\n",
    "    # 0.1 √âlimination critique : Lignes sans valeur cible (Target)\n",
    "    # --------------------------------------------------------------------------\n",
    "    nb_avant         = len(df_work)\n",
    "    df_work          = df_work.dropna(subset=[target])\n",
    "    nb_apres         = len(df_work)\n",
    "    \n",
    "    if nb_avant != nb_apres:\n",
    "        print(f\"‚ö†Ô∏è Nettoyage Target...: {nb_avant - nb_apres} lignes supprim√©es\")\n",
    "\n",
    "    # 0.2 Suppression des colonnes constantes ou non informatives\n",
    "    # --------------------------------------------------------------------------\n",
    "    cols_a_supprimer = ['DataYear', 'City', 'State', 'Comments', \n",
    "                        'Outlier', 'OSEBuildingID', 'Electricity(kWh)']\n",
    "    \n",
    "    df_work          = df_work.drop(columns=cols_a_supprimer, errors='ignore')\n",
    "\n",
    "    # 0.3 S√©paration des caract√©ristiques et de la cible\n",
    "    # --------------------------------------------------------------------------\n",
    "    y                = df_work[target]\n",
    "    x                = df_work.drop(columns=[target])\n",
    "\n",
    "    return x, y\n",
    "    \n",
    "# ##############################################################################\n",
    "# √âTAPE 1 : IDENTIFICATION ET TYPAGE DES COLONNES\n",
    "# ##############################################################################\n",
    "\n",
    "def identifier_colonnes(df_x):\n",
    "    \"\"\"\n",
    "    Cat√©gorise les variables pour orienter les strat√©gies de transformation.\n",
    "    \"\"\"\n",
    "    # 1.1 Variables num√©riques continues (Consommation, Surface, Localisation)\n",
    "    numeriques       = ['Latitude', 'Longitude', 'YearBuilt', 'NumberofBuildings',\n",
    "                        'NumberofFloors', 'PropertyGFATotal', \n",
    "                        'PropertyGFAParking', 'PropertyGFABuilding(s)',\n",
    "                        'LargestPropertyUseTypeGFA', \n",
    "                        'SecondLargestPropertyUseTypeGFA',\n",
    "                        'ThirdLargestPropertyUseTypeGFA', 'ENERGYSTARScore',\n",
    "                        'SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)',\n",
    "                        'SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)',\n",
    "                        'SteamUse(kBtu)', 'Electricity(kBtu)',\n",
    "                        'NaturalGas(therms)', 'NaturalGas(kBtu)',\n",
    "                        'TotalGHGEmissions', 'GHGEmissionsIntensity']\n",
    "\n",
    "    # 1.2 Variables n√©cessitant une transformation logarithmique\n",
    "    cols_log         = ['PropertyGFATotal', 'PropertyGFABuilding(s)',\n",
    "                        'LargestPropertyUseTypeGFA', 'SiteEUI(kBtu/sf)', \n",
    "                        'SourceEUI(kBtu/sf)', 'SteamUse(kBtu)', \n",
    "                        'Electricity(kBtu)', 'NaturalGas(kBtu)',\n",
    "                        'TotalGHGEmissions']\n",
    "\n",
    "    # 1.3 Variables cat√©gorielles (Basse et Haute cardinalit√©)\n",
    "    cat_ohe          = ['PrimaryPropertyType', 'BuildingType', \n",
    "                        'CouncilDistrictCode']\n",
    "    cat_target       = ['Neighborhood']\n",
    "\n",
    "    # 1.4 Variables n√©cessitant un indicateur de pr√©sence de vide\n",
    "    cols_indic       = ['SecondLargestPropertyUseTypeGFA', \n",
    "                        'ThirdLargestPropertyUseTypeGFA', 'ENERGYSTARScore']\n",
    "\n",
    "    # Filtrage par intersection pour garantir la pr√©sence dans le DataFrame\n",
    "    return {\n",
    "        'num_cont'   : [c for c in numeriques if c in df_x.columns],\n",
    "        'num_log'    : [c for c in cols_log  if c in df_x.columns],\n",
    "        'cat_ohe'    : [c for c in cat_ohe   if c in df_x.columns],\n",
    "        'cat_target' : [c for c in cat_target if c in df_x.columns],\n",
    "        'indic_nan'  : [c for c in cols_indic if c in df_x.columns]\n",
    "    }\n",
    "\n",
    "# ##############################################################################\n",
    "# √âTAPE 2 : LOGIQUE DES TRANSFORMATEURS PERSONNALIS√âS\n",
    "# ##############################################################################\n",
    "\n",
    "def log_transform(df_x):\n",
    "    \"\"\"Applique log(1+x) avec gestion des valeurs n√©gatives.\"\"\"\n",
    "    df_x             = df_x.copy()\n",
    "    for col in df_x.columns:\n",
    "        if df_x[col].min() < 0:\n",
    "            offset   = abs(df_x[col].min()) + 1\n",
    "            df_x[col] = np.log1p(df_x[col] + offset)\n",
    "        else:\n",
    "            df_x[col] = np.log1p(df_x[col])\n",
    "    return df_x\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def winsorize_transform(df_x, lower=0.01, upper=0.99):\n",
    "    \"\"\"Limite les valeurs extr√™mes aux percentiles d√©finis.\"\"\"\n",
    "    df_x             = df_x.copy()\n",
    "    for col in df_x.columns:\n",
    "        q_low        = df_x[col].quantile(lower)\n",
    "        q_high       = df_x[col].quantile(upper)\n",
    "        df_x[col]    = df_x[col].clip(lower=q_low, upper=q_high)\n",
    "    return df_x\n",
    "\n",
    "# On cr√©e des fonctions simples qui appellent les originales avec les bons param√®tres\n",
    "# Cela remplace les lambdas qui bloquent le joblib.dump\n",
    "def wrapper_winsorize(df_x):\n",
    "    return winsorize_transform(df_x, lower=0.01, upper=0.99)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def create_features(df_x):\n",
    "    \"\"\"G√©n√®re de nouvelles variables m√©tier (Feature Engineering).\"\"\"\n",
    "    df_x             = df_x.copy()\n",
    "\n",
    "    # Ratios d'efficacit√© √©nerg√©tique et environnementale\n",
    "    if 'TotalGHGEmissions' in df_x.columns and 'PropertyGFATotal' in df_x.columns:\n",
    "        df_x['GHG_Density']    = df_x['TotalGHGEmissions'] / \\\n",
    "                                 (df_x['PropertyGFATotal'] + 1)\n",
    "\n",
    "    if 'SecondLargestPropertyUseTypeGFA' in df_x.columns:\n",
    "        df_x['Multi_Usage']    = (df_x['SecondLargestPropertyUseTypeGFA'] > 0)\\\n",
    "                                 .astype(int)\n",
    "\n",
    "    if 'ENERGYSTARScore' in df_x.columns:\n",
    "        df_x['Energy_Level']   = pd.cut(df_x['ENERGYSTARScore'], \n",
    "                                        bins=[0, 50, 75, 100],\n",
    "                                        labels=['Low', 'Med', 'High'],\n",
    "                                        include_lowest=True).astype(str)\n",
    "    return df_x\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def create_missing_indicators(df_x, cols_to_flag):\n",
    "    \"\"\"Cr√©e des drapeaux binaires pour les valeurs manquantes importantes.\"\"\"\n",
    "    df_x             = df_x.copy()\n",
    "    for col in cols_to_flag:\n",
    "        if col in df_x.columns:\n",
    "            df_x[f'{col}_Nan'] = df_x[col].isna().astype(int)\n",
    "    return df_x\n",
    "\n",
    "# On cr√©e des fonctions simples qui appellent les originales avec les bons param√®tres\n",
    "# Cela remplace les lambdas qui bloquent le joblib.dump\n",
    "def wrapper_missing_indicators(df_x, cols_to_flag):\n",
    "    return create_missing_indicators(df_x, cols_to_flag)\n",
    "    \n",
    "# ##############################################################################\n",
    "# √âTAPE 3 : CONSTRUCTION DU PIPELINE DE PR√âTRAITEMENT\n",
    "# ##############################################################################\n",
    "\n",
    "def build_preprocessing_pipeline(df_x, v_y=None):\n",
    "    \"\"\"Assemble les briques de transformation dans un ColumnTransformer.\"\"\"\n",
    "    info             = identifier_colonnes(df_x)\n",
    "\n",
    "    # 3.1 Sous-pipeline : Num√©rique avec Log\n",
    "    pipe_num_log     = Pipeline(steps=[\n",
    "        ('log',      FunctionTransformer(log_transform, validate=False)),\n",
    "        ('winsor',   FunctionTransformer(winsorize_transform, validate=False,\n",
    "                                         kw_args={'lower': 0.01, \n",
    "                                                  'upper': 0.99})),\n",
    "        ('imputer',  SimpleImputer(strategy='median')),\n",
    "        ('scaler',   StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # 3.2 Sous-pipeline : Cat√©goriel One-Hot\n",
    "    pipe_cat_ohe     = Pipeline(steps=[\n",
    "        ('imputer',  SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "        ('ohe',      OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # 3.3 Sous-pipeline : Target Encoding\n",
    "    pipe_target      = Pipeline(steps=[\n",
    "        ('imputer',  SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "        ('target',   TargetEncoder(smoothing=10, min_samples_leaf=20))\n",
    "    ])\n",
    "\n",
    "    # Construction des transformateurs\n",
    "    dispatch         = [\n",
    "        ('n_log',    pipe_num_log, info['num_log']),\n",
    "        ('c_ohe',    pipe_cat_ohe, info['cat_ohe'])\n",
    "    ]\n",
    "\n",
    "    if v_y is not None and info['cat_target']:\n",
    "        dispatch.append(('c_target', pipe_target, info['cat_target']))\n",
    "\n",
    "    preprocessor     = ColumnTransformer(transformers=dispatch, remainder='drop')\n",
    "\n",
    "    # Pipeline global int√©grant le feature engineering\n",
    "    return Pipeline(steps=[\n",
    "        ('nan_flags', FunctionTransformer(create_missing_indicators, \n",
    "                                                  validate=False,\n",
    "                                                  kw_args={'cols_to_flag': \n",
    "                                                           info['indic_nan']})),\n",
    "        ('feat_eng',  FunctionTransformer(create_features, validate=False)),\n",
    "        ('preproc',   preprocessor)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cd6c6-3c62-4899-9364-e61a006fb979",
   "metadata": {},
   "source": [
    "# 1. ‚öôÔ∏è Initialisation du PRE-PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1b4ab87-18d8-47c3-87f1-6e6bf6d5bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du pipeline de traitement\n",
    "pre_pipeline         = build_preprocessing_pipeline(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3898b7c-1722-429a-a2b2-daa0454784b7",
   "metadata": {},
   "source": [
    "# 2. ‚öôÔ∏è CONFIGURATION DU BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ef19fd8-207d-46cd-90ff-65f0b8cb2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION DU PROTOCOLE D'√âVALUATION (VALIDATION CROIS√âE)\n",
    "# ============================================================================\n",
    "# D√©finition de la strat√©gie de validation crois√©e (5-Fold)\n",
    "# On utilise shuffle=True pour garantir l'ind√©pendance des √©chantillons.\n",
    "# La constante SEED assure la reproductibilit√© du d√©coupage.\n",
    "cv               = KFold(\n",
    "                   n_splits     = 5, \n",
    "                   shuffle      = True, \n",
    "                   random_state = 42\n",
    ")\n",
    "\n",
    "# D√©finition des m√©triques de performance pour la comparaison\n",
    "# 'neg_' indique que Scikit-Learn maximise l'oppos√© de l'erreur.\n",
    "scoring          = {\n",
    "    \"r2\"         : \"r2\",                                # Pr√©cision R¬≤\n",
    "    \"mae\"        : \"neg_mean_absolute_error\",           # Erreur MAE (Moyenne)\n",
    "    \"rmse\"       : \"neg_root_mean_squared_error\",       # Erreur RMSE (√âcart)\n",
    "}\n",
    "\n",
    "# D√©finition des algorithmes √† challenger\n",
    "models               = {\n",
    "    # Mod√®le de r√©f√©rence : pr√©dit syst√©matiquement la moyenne du jeu d'entra√Ænement\n",
    "    \"Baseline (Moyenne)\"  : DummyRegressor(strategy=\"mean\"),\n",
    "\n",
    "    # Mod√®le lin√©aire : cherche une relation directe entre les variables et la cible\n",
    "    \"R√©gression Lin√©aire\" : LinearRegression(),\n",
    "\n",
    "    # Mod√®le non-lin√©aire (SVR) : utilise des noyaux pour projeter les donn√©es dans un espace sup√©rieur\n",
    "    \"SVR (RBF)\"           : SVR(kernel=\"rbf\", C=1.0, epsilon=0.1),\n",
    "\n",
    "    # Mod√®le d'ensemble (Random Forest) : agr√©gation de 100 arbres de d√©cision pour r√©duire la variance\n",
    "    \"Random Forest\"       : RandomForestRegressor(\n",
    "                            n_estimators = 100,             # Nombre d'arbres dans la for√™t\n",
    "                            max_depth    = 10,              # Limite de profondeur pour √©viter l'overfit\n",
    "                            random_state = 42,            # Graine pour la reproductibilit√©\n",
    "                            n_jobs       = -1)              # Utilisation de tous les processeurs disponibles\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ff908-023c-47f6-a6f2-48870ae35e9e",
   "metadata": {},
   "source": [
    "# 3. ‚è≥ BENCHMARK DES MOD√àLES : EXTRACTION D√âTAILL√âE ET √âVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a72255b1-5755-431d-a457-a5cbab249948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "ü§ñ MOD√âLISATION - Comparaison via Cross-Validation\n",
      "============================================================================\n",
      "\n",
      "üîÑ Cross-validation pour Baseline (Moyenne)...\n",
      "‚úÖ Baseline (Moyenne)\n",
      "   R¬≤   train..: 0.0000 | CV: -0.0010 ¬± 0.0010\n",
      "   MAE  train..: 5405347.92 | CV: 5403874.72 ¬± 417144.62\n",
      "   RMSE train..: 15271001.74 | CV: 14606281.39 ¬± -4614216.86\n",
      "   ‚úÖ Bon √©quilibre train/CV\n",
      "\n",
      "üîÑ Cross-validation pour R√©gression Lin√©aire...\n",
      "‚úÖ R√©gression Lin√©aire\n",
      "   R¬≤   train..: 0.4908 | CV: 0.4259 ¬± 0.1664\n",
      "   MAE  train..: 3984754.81 | CV: 4490683.10 ¬± 189872.68\n",
      "   RMSE train..: 10913064.24 | CV: 11215698.42 ¬± -4763989.50\n",
      "   ‚úÖ Bon √©quilibre train/CV\n",
      "\n",
      "üîÑ Cross-validation pour SVR (RBF)...\n",
      "‚úÖ SVR (RBF)\n",
      "   R¬≤   train..: -0.0477 | CV: -0.0629 ¬± 0.0263\n",
      "   MAE  train..: 4121293.92 | CV: 4123643.17 ¬± 396142.28\n",
      "   RMSE train..: 15628047.50 | CV: 14992698.65 ¬± -4554825.86\n",
      "   ‚úÖ Bon √©quilibre train/CV\n",
      "\n",
      "üîÑ Cross-validation pour Random Forest...\n",
      "‚úÖ Random Forest\n",
      "   R¬≤   train..: 0.9468 | CV: 0.6790 ¬± 0.2127\n",
      "   MAE  train..: 349970.94 | CV: 914506.43 ¬± 262550.69\n",
      "   RMSE train..: 3531794.36 | CV: 8597691.94 ¬± -5266614.81\n",
      "   ‚ö†Ô∏è  Surapprentissage probable (√©cart R¬≤ = 0.2678)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BENCHMARK DES MOD√àLES : EXTRACTION D√âTAILL√âE ET √âVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Initialisation de la structure de stockage\n",
    "# Cette liste contiendra les dictionnaires de m√©triques pour chaque mod√®le.\n",
    "results_list     = []                                        # Initialisation\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n============================================================================\")\n",
    "print(\"ü§ñ MOD√âLISATION - Comparaison via Cross-Validation\")\n",
    "print(\"============================================================================\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Cross-validation pour {name}...\")\n",
    "    \n",
    "    # Cr√©ation du pipeline complet : Pr√©traitement + Mod√®le\n",
    "    # Cette structure √©vite toute fuite de donn√©es (Data Leakage).\n",
    "    full_pipe        = Pipeline(steps=[(\"prep\", pre_pipeline), (\"model\", model)])\n",
    "    \n",
    "    # Ex√©cution de la validation crois√©e\n",
    "    cv_res             = cross_validate(\n",
    "                         full_pipe, \n",
    "                         X_train, \n",
    "                         y_train, \n",
    "                         cv                 = kf,\n",
    "                         scoring            = scoring,\n",
    "                         n_jobs             = -1,\n",
    "                         return_train_score = True\n",
    "    )\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # EXTRACTION EXPLICITE DES M√âTRIQUES (MOYENNES ET √âCARTS-TYPES)\n",
    "    # ------------------------------------------------------------------------\n",
    "    \n",
    "    # M√©triques R¬≤ (Coefficient de d√©termination)\n",
    "    r2_train_mean      = cv_res[\"train_r2\"].mean()              # Moyenne Train\n",
    "    r2_test_mean       = cv_res[\"test_r2\"].mean()               # Moyenne CV\n",
    "    r2_test_std        = cv_res[\"test_r2\"].std()                # √âcart-type CV\n",
    "    \n",
    "    # M√©triques MAE (Erreur Absolue Moyenne)\n",
    "    # Note : On multiplie par -1 car Scikit-Learn retourne des valeurs n√©gatives\n",
    "    mae_train_mean     = -cv_res[\"train_mae\"].mean()            # Moyenne Train\n",
    "    mae_test_mean      = -cv_res[\"test_mae\"].mean()             # Moyenne CV\n",
    "    mae_test_std       = cv_res[\"test_mae\"].std()               # √âcart-type CV\n",
    "    \n",
    "    # M√©triques RMSE (Erreur Quadratique Moyenne Racine)\n",
    "    rmse_train_mean    = -cv_res[\"train_rmse\"].mean()           # Moyenne Train\n",
    "    rmse_test_mean     = -cv_res[\"test_rmse\"].mean()            # Moyenne CV\n",
    "    rmse_test_std      = -cv_res[\"test_rmse\"].std()             # √âcart-type CV\n",
    "    \n",
    "    # Calcul de l'√©cart de g√©n√©ralisation (Overfit Gap)\n",
    "    overfit_gap        = r2_train_mean - r2_test_mean           # √âcart R¬≤\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # AFFICHAGE DU RAPPORT DE PERFORMANCE\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(f\"‚úÖ {name}\")\n",
    "    print(f\"   R¬≤   train..: {r2_train_mean:.4f} | CV: {r2_test_mean:.4f} \"\n",
    "          f\"¬± {r2_test_std:.4f}\")\n",
    "    print(f\"   MAE  train..: {mae_train_mean:.2f} | CV: {mae_test_mean:.2f} \"\n",
    "          f\"¬± {mae_test_std:.2f}\")\n",
    "    print(f\"   RMSE train..: {rmse_train_mean:.2f} | CV: {rmse_test_mean:.2f} \"\n",
    "          f\"¬± {rmse_test_std:.2f}\")\n",
    "    \n",
    "    # Diagnostic du comportement du mod√®le\n",
    "    if   overfit_gap >  0.10:\n",
    "        print(f\"   ‚ö†Ô∏è  Surapprentissage probable (√©cart R¬≤ = {overfit_gap:.4f})\")\n",
    "    elif overfit_gap < -0.05:\n",
    "        print(f\"   ‚ö†Ô∏è  Sous-apprentissage possible\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Bon √©quilibre train/CV\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # ARCHIVAGE DANS LA STRUCTURE DE DONN√âES FINALE\n",
    "    # ------------------------------------------------------------------------\n",
    "    results_list.append({\n",
    "        \"Mod√®le\"          : name,\n",
    "        \"R¬≤ CV (mean)\"    : r2_test_mean,\n",
    "        \"R¬≤ CV (std)\"     : r2_test_std,\n",
    "        \"MAE CV (mean)\"   : mae_test_mean,\n",
    "        \"MAE CV (std)\"    : mae_test_std,\n",
    "        \"RMSE CV (mean)\"  : rmse_test_mean,\n",
    "        \"RMSE CV (std)\"   : rmse_test_std,\n",
    "        \"R¬≤ train (mean)\" : r2_train_mean,\n",
    "        \"Overfit gap (R¬≤)\": overfit_gap\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801c407-386a-4ec5-b5b8-aa851cb42d29",
   "metadata": {},
   "source": [
    "# 4. üë§ ANALYSE COMPARATIVE ET S√âLECTION DU MOD√àLE OPTIMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36e7e749-235a-43d1-bf8e-ffe749b6f405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "üìä TABLEAU R√âCAPITULATIF (Performance Cross-Validation sur Train Set)\n",
      "============================================================================\n",
      "Mod√®le               R¬≤ CV (mean)  R¬≤ CV (std)  MAE CV (mean)  MAE CV (std)  RMSE CV (mean)  RMSE CV (std)  R¬≤ train (mean)  Overfit gap (R¬≤)\n",
      "      Random Forest  0.6790       0.2127        914506.4326   262550.6909    8597691.9446   -5266614.8115   0.9468          0.2678           \n",
      "R√©gression Lin√©aire  0.4259       0.1664       4490683.1035   189872.6753   11215698.4195   -4763989.4994   0.4908          0.0649           \n",
      " Baseline (Moyenne) -0.0010       0.0010       5403874.7179   417144.6171   14606281.3938   -4614216.8551   0.0000          0.0010           \n",
      "          SVR (RBF) -0.0629       0.0263       4123643.1744   396142.2756   14992698.6475   -4554825.8603  -0.0477          0.0152           \n",
      "============================================================================\n",
      "üèÜ MEILLEUR MOD√àLE D√âTECT√â : Random Forest  (selon R¬≤ CV mean)\n",
      "üìà Score R¬≤ de r√©f√©rence ..: 0.6790\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ANALYSE COMPARATIVE ET S√âLECTION DU MOD√àLE OPTIMAL\n",
    "# ============================================================================\n",
    "\n",
    "# Cr√©ation du DataFrame r√©capitulatif √† partir des r√©sultats collect√©s\n",
    "# Le tri par R¬≤ CV (mean) place le mod√®le le plus performant au sommet.\n",
    "comparison_df    = pd.DataFrame(results_list).sort_values(\n",
    "                   by        = \"R¬≤ CV (mean)\", \n",
    "                   ascending = False\n",
    ")\n",
    "\n",
    "# Extraction automatique du vainqueur pour la suite du pipeline\n",
    "best_model_name  = comparison_df.iloc[0][\"Mod√®le\"]\n",
    "best_r2_score    = comparison_df.iloc[0][\"R¬≤ CV (mean)\"]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# AFFICHAGE DU CLASSEMENT FINAL\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n============================================================================\")\n",
    "print(\"üìä TABLEAU R√âCAPITULATIF (Performance Cross-Validation sur Train Set)\")\n",
    "print(\"============================================================================\")\n",
    "\n",
    "# Utilisation de to_string pour garantir l'alignement strict des colonnes\n",
    "print(comparison_df.to_string(\n",
    "      index      = False, \n",
    "      justify    = 'left', \n",
    "      float_format = lambda x: f\"{x:.4f}\" if isinstance(x, float) else x\n",
    "))\n",
    "\n",
    "print(\"============================================================================\")\n",
    "print(f\"üèÜ MEILLEUR MOD√àLE D√âTECT√â : {best_model_name}  (selon R¬≤ CV mean)\")\n",
    "print(f\"üìà Score R¬≤ de r√©f√©rence ..: {best_r2_score:.4f}\")\n",
    "print(\"============================================================================\")\n",
    "\n",
    "# ############################################################################\n",
    "# INTERPR√âTATION \n",
    "# ############################################################################\n",
    "# Le choix du mod√®le ne doit pas se baser uniquement sur le R¬≤ moyen.\n",
    "# V√©rifiez √©galement le 'R¬≤ CV (std)' : un mod√®le stable pr√©sente un \n",
    "# √©cart-type faible, garantissant sa robustesse sur des donn√©es inconnues.\n",
    "# ############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139ac19-be1e-4ec9-a18d-5b414ad23c03",
   "metadata": {},
   "source": [
    "# 5. ‚è≥ ENTRA√éNEMENT DU MOD√àLE FINAL (PRODUCTION READY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3804f9cd-a569-4921-8469-0332056fb9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "üì¶ ENTRA√éNEMENT DU MOD√àLE OPTIMAL : Random Forest\n",
      "============================================================================\n",
      "\n",
      "üöÄ Entra√Ænement final de Random Forest sur le jeu complet...\n",
      "\n",
      "============================================================================\n",
      "BILAN FINAL DU PIPELINE\n",
      "============================================================================\n",
      "  Mod√®le entra√Æn√©.....: Random Forest\n",
      "  Performance R¬≤ Test.: 0.2923\n",
      "============================================================================\n",
      "\n",
      "‚úÖ Pipeline sauvegard√© : 'best_model_pipeline.pkl'\n",
      "   √âtat du mod√®le.....: ENTRA√éN√â (FIT OK)\n",
      "   Taille disque......: 4119.89 KB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENTRA√éNEMENT DU MOD√àLE FINAL (PRODUCTION READY)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n============================================================================\")\n",
    "print(f\"üì¶ ENTRA√éNEMENT DU MOD√àLE OPTIMAL : {best_model_name}\")\n",
    "print(\"============================================================================\")\n",
    "\n",
    "# Extraction du pr√©processeur complet (incluant Feature Engineering)\n",
    "# On r√©cup√®re l'objet pipeline de traitement que nous avons test√© en CV\n",
    "final_preprocessor = pre_pipeline\n",
    "\n",
    "# Choix de l'estimateur (Meilleur mod√®le identifi√© √† l'√©tape 6)\n",
    "best_estimator     = models[best_model_name]\n",
    "\n",
    "# Assemblage final\n",
    "# Ici, 'final_preprocessor' contient d√©j√† : nan_flags + feat_eng + preproc\n",
    "best_pipeline      = Pipeline(steps=[\n",
    "    (\"preprocess\", final_preprocessor),       # Tout le flux de traitement\n",
    "    (\"model\",      best_estimator)            # L'intelligence pr√©dictive\n",
    "])\n",
    "\n",
    "# Apprentissage (C'est ici que le mod√®le \"apprend\" de X_train)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(f\"\\nüöÄ Entra√Ænement final de {best_model_name} sur le jeu complet...\")\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Mesure de performance sur les donn√©es jamais vues (X_test)\n",
    "# ------------------------------------------------------------------------------\n",
    "y_pred_final     = best_pipeline.predict(X_test)\n",
    "best_r2_score    = r2_score(y_test, y_pred_final)\n",
    "\n",
    "# Rapport de cl√¥ture du projet\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n============================================================================\")\n",
    "print(\"BILAN FINAL DU PIPELINE\")\n",
    "print(\"============================================================================\")\n",
    "print(f\"  Mod√®le entra√Æn√©.....: {best_model_name}\")\n",
    "print(f\"  Performance R¬≤ Test.: {best_r2_score:.4f}\")\n",
    "print(\"============================================================================\")\n",
    "\n",
    "# Sauvegarde du binaire (Pr√™t pour la production)\n",
    "# ------------------------------------------------------------------------------\n",
    "nom_fichier      = 'best_model_pipeline.pkl'\n",
    "\n",
    "try:\n",
    "    joblib.dump(best_pipeline, nom_fichier)\n",
    "    print(f\"\\n‚úÖ Pipeline sauvegard√© : '{nom_fichier}'\")\n",
    "    print(f\"   √âtat du mod√®le.....: ENTRA√éN√â (FIT OK)\")\n",
    "    print(f\"   Taille disque......: {os.path.getsize(nom_fichier) / 1024:.2f} KB\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå √âCHEC DE LA SAUVEGARDE : {str(e)}\")\n",
    "# ############################################################################\n",
    "# ANALYSE TECHNIQUE \n",
    "# ############################################################################\n",
    "# Ce 'best_pipeline' est d√©sormais un objet autonome. Il peut recevoir des \n",
    "# donn√©es brutes (raw data), les transformer selon les r√®gles du \n",
    "# 'preprocessor' et fournir une pr√©diction sans intervention manuelle.\n",
    "# ############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f4ca9-c8ca-4008-9c00-33170f3b40e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb1d1f-c0a9-49f5-bd61-b12022a1dcad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
