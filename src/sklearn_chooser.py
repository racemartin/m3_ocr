"""
Scikit-learn Algorithm Chooser
Bas√© sur le flowchart officiel de scikit-learn
"""

from typing import Dict, List, Tuple
from dataclasses import dataclass
from enum import Enum


class TaskType(Enum):
    """Types de t√¢ches ML"""
    CLASSIFICATION = "classification"
    REGRESSION = "regression"
    CLUSTERING = "clustering"
    DIMENSIONALITY_REDUCTION = "dimensionality_reduction"


@dataclass
class ModelRecommendation:
    """Recommandation de mod√®le"""
    name: str
    sklearn_class: str
    description: str
    parameters: Dict[str, str]
    notes: List[str]


class ScikitLearnChooser:
    """Choisisseur d'algorithme scikit-learn selon le flowchart"""
    
    def __init__(self):
        self.history = []
    
    def choose_algorithm(
        self,
        n_samples: int,
        task: str,
        has_labeled_data: bool = True,
        predicting_category: bool = True,
        predicting_quantity: bool = False,
        n_features: int = None,
        text_data: bool = False,
        need_structure: bool = False,
        tough_luck: bool = False
    ) -> ModelRecommendation:
        """
        Choisit l'algorithme appropri√© selon le flowchart scikit-learn.
        
        Args:
            n_samples: Nombre d'√©chantillons
            task: Type de t√¢che ('classification', 'regression', 'clustering', 'dimensionality_reduction')
            has_labeled_data: Les donn√©es sont-elles √©tiquet√©es?
            predicting_category: Pr√©dire une cat√©gorie?
            predicting_quantity: Pr√©dire une quantit√©?
            n_features: Nombre de features
            text_data: Donn√©es textuelles?
            need_structure: Besoin de structure?
            tough_luck: Probl√®me difficile?
        
        Returns:
            ModelRecommendation: Recommandation de mod√®le
        """
        
        # START: Obtenir les donn√©es √©tiquet√©es
        if not has_labeled_data:
            return self._choose_unsupervised(n_samples, n_features, need_structure)
        
        # Donn√©es √©tiquet√©es
        if n_samples < 50:
            return ModelRecommendation(
                name="Get more data",
                sklearn_class="N/A",
                description="Vous avez besoin de plus de donn√©es (< 50 √©chantillons)",
                parameters={},
                notes=["Collectez plus d'√©chantillons avant d'entra√Æner un mod√®le"]
            )
        
        # Classification ou R√©gression?
        if predicting_category:
            return self._choose_classification(n_samples, text_data, tough_luck)
        
        if predicting_quantity:
            return self._choose_regression(n_samples, n_features)
        
        # Par d√©faut, demander plus d'informations
        return ModelRecommendation(
            name="Need more information",
            sklearn_class="N/A",
            description="Pr√©cisez si vous pr√©disez une cat√©gorie ou une quantit√©",
            parameters={},
            notes=["D√©finissez clairement votre probl√®me"]
        )
    
    def _choose_classification(
        self, 
        n_samples: int, 
        text_data: bool,
        tough_luck: bool
    ) -> ModelRecommendation:
        """Choisit un algorithme de classification"""
        
        if n_samples < 100_000:
            # < 100K samples
            if text_data:
                return ModelRecommendation(
                    name="Naive Bayes",
                    sklearn_class="sklearn.naive_bayes.MultinomialNB",
                    description="Id√©al pour la classification de texte",
                    parameters={
                        "alpha": "1.0 (smoothing parameter)"
                    },
                    notes=[
                        "Tr√®s rapide",
                        "Fonctionne bien avec peu de donn√©es",
                        "Bon pour le text mining"
                    ]
                )
            
            # Essayer Linear SVC
            return ModelRecommendation(
                name="Linear SVC",
                sklearn_class="sklearn.svm.LinearSVC",
                description="Support Vector Classification avec noyau lin√©aire",
                parameters={
                    "C": "1.0 (regularization)",
                    "max_iter": "1000"
                },
                notes=[
                    "Efficace pour donn√©es lin√©airement s√©parables",
                    "Rapide sur datasets moyens",
                    "Si √ßa ne marche pas, essayez KNeighborsClassifier ou SVC"
                ]
            )
        
        else:
            # >= 100K samples
            return ModelRecommendation(
                name="SGD Classifier",
                sklearn_class="sklearn.linear_model.SGDClassifier",
                description="Classificateur avec descente de gradient stochastique",
                parameters={
                    "loss": "'hinge' or 'log_loss'",
                    "alpha": "0.0001 (regularization)",
                    "max_iter": "1000"
                },
                notes=[
                    "Tr√®s efficace sur grands datasets",
                    "Scalable",
                    "Supporte l'apprentissage incr√©mental"
                ]
            )
    
    def _choose_regression(
        self, 
        n_samples: int,
        n_features: int = None
    ) -> ModelRecommendation:
        """Choisit un algorithme de r√©gression"""
        
        if n_samples < 100_000:
            # < 100K samples
            if n_features and n_features > 100:
                # Few features should be important
                return ModelRecommendation(
                    name="Lasso (L1) / ElasticNet",
                    sklearn_class="sklearn.linear_model.Lasso",
                    description="R√©gression lin√©aire avec r√©gularisation L1",
                    parameters={
                        "alpha": "1.0 (regularization strength)"
                    },
                    notes=[
                        "Effectue une s√©lection de features automatique",
                        "Met certains coefficients √† z√©ro",
                        "ElasticNet combine L1 et L2"
                    ]
                )
            else:
                # Regular regression
                return ModelRecommendation(
                    name="Ridge Regression (L2)",
                    sklearn_class="sklearn.linear_model.Ridge",
                    description="R√©gression lin√©aire avec r√©gularisation L2",
                    parameters={
                        "alpha": "1.0 (regularization strength)"
                    },
                    notes=[
                        "Bonne pour la plupart des probl√®mes",
                        "R√©duit l'overfitting",
                        "Plus stable que Lasso"
                    ]
                )
        else:
            # >= 100K samples
            return ModelRecommendation(
                name="SGD Regressor",
                sklearn_class="sklearn.linear_model.SGDRegressor",
                description="R√©gression avec descente de gradient stochastique",
                parameters={
                    "loss": "'squared_error'",
                    "alpha": "0.0001",
                    "max_iter": "1000"
                },
                notes=[
                    "Tr√®s rapide sur gros datasets",
                    "Scalable",
                    "Supporte l'apprentissage en ligne"
                ]
            )
    
    def _choose_unsupervised(
        self,
        n_samples: int,
        n_features: int = None,
        need_structure: bool = False
    ) -> ModelRecommendation:
        """Choisit un algorithme non supervis√©"""
        
        # Clustering ou Dimensionality Reduction?
        if need_structure:
            # Dimensionality Reduction
            if n_samples < 10_000:
                return ModelRecommendation(
                    name="IsoMap",
                    sklearn_class="sklearn.manifold.Isomap",
                    description="Isometric Mapping pour r√©duction de dimensionnalit√©",
                    parameters={
                        "n_components": "2 or 3",
                        "n_neighbors": "5"
                    },
                    notes=[
                        "Pr√©serve les distances g√©od√©siques",
                        "Bon pour la visualisation",
                        "Peut √™tre lent sur gros datasets"
                    ]
                )
            else:
                return ModelRecommendation(
                    name="Kernel Approximation + LLE",
                    sklearn_class="sklearn.decomposition.KernelPCA",
                    description="Approximation de noyau avec Locally Linear Embedding",
                    parameters={
                        "n_components": "depends on use case",
                        "kernel": "'rbf' or 'poly'"
                    },
                    notes=[
                        "Scalable",
                        "Pr√©serve la structure locale",
                        "Spectral Embedding ou LLE sont aussi possibles"
                    ]
                )
        
        else:
            # Clustering
            if n_samples < 10_000:
                # Small dataset
                return ModelRecommendation(
                    name="KMeans",
                    sklearn_class="sklearn.cluster.KMeans",
                    description="Clustering par K-moyennes",
                    parameters={
                        "n_clusters": "must be specified",
                        "init": "'k-means++'",
                        "n_init": "10"
                    },
                    notes=[
                        "Simple et efficace",
                        "N√©cessite de conna√Ætre K √† l'avance",
                        "Sensible aux outliers"
                    ]
                )
            else:
                # Large dataset
                return ModelRecommendation(
                    name="MiniBatch KMeans",
                    sklearn_class="sklearn.cluster.MiniBatchKMeans",
                    description="KMeans avec mini-batches pour grands datasets",
                    parameters={
                        "n_clusters": "must be specified",
                        "batch_size": "100"
                    },
                    notes=[
                        "Plus rapide que KMeans classique",
                        "Scalable",
                        "L√©ger compromis sur la qualit√©"
                    ]
                )
    
    def interactive_chooser(self):
        """Mode interactif pour choisir un algorithme"""
        print("=" * 60)
        print("ü§ñ SCIKIT-LEARN ALGORITHM CHOOSER")
        print("=" * 60)
        print()
        
        # Question 1: Nombre d'√©chantillons
        while True:
            try:
                n_samples = int(input("üìä Combien d'√©chantillons avez-vous? "))
                if n_samples < 0:
                    print("‚ùå Le nombre doit √™tre positif!")
                    continue
                break
            except ValueError:
                print("‚ùå Entrez un nombre valide!")
        
        if n_samples < 50:
            print("\n‚ö†Ô∏è  Vous avez besoin de plus de donn√©es (< 50 √©chantillons)")
            print("üí° Collectez plus d'√©chantillons avant d'entra√Æner un mod√®le")
            return
        
        print()
        
        # Question 2: Donn√©es √©tiquet√©es?
        labeled = input("üè∑Ô∏è  Avez-vous des donn√©es √©tiquet√©es? (oui/non): ").lower().strip()
        has_labeled_data = labeled in ['oui', 'o', 'yes', 'y']
        
        if not has_labeled_data:
            print()
            structure = input("üîç Cherchez-vous une structure dans les donn√©es? (oui/non): ").lower().strip()
            need_structure = structure in ['oui', 'o', 'yes', 'y']
            
            recommendation = self._choose_unsupervised(n_samples, need_structure=need_structure)
            self._display_recommendation(recommendation)
            return
        
        print()
        
        # Question 3: Classification ou R√©gression?
        print("üéØ Que voulez-vous pr√©dire?")
        print("  1. Une cat√©gorie (classification)")
        print("  2. Une quantit√© (r√©gression)")
        
        choice = input("Votre choix (1/2): ").strip()
        
        if choice == "1":
            # Classification
            print()
            text = input("üìù Travaillez-vous avec des donn√©es textuelles? (oui/non): ").lower().strip()
            text_data = text in ['oui', 'o', 'yes', 'y']
            
            recommendation = self._choose_classification(n_samples, text_data, False)
            
        elif choice == "2":
            # R√©gression
            print()
            try:
                n_features_str = input("üìà Combien de features? (appuyez sur Entr√©e si inconnu): ").strip()
                n_features = int(n_features_str) if n_features_str else None
            except ValueError:
                n_features = None
            
            recommendation = self._choose_regression(n_samples, n_features)
        
        else:
            print("‚ùå Choix invalide!")
            return
        
        self._display_recommendation(recommendation)
    
    def _display_recommendation(self, rec: ModelRecommendation):
        """Affiche la recommandation de mani√®re lisible"""
        print()
        print("=" * 60)
        print("‚úÖ RECOMMANDATION")
        print("=" * 60)
        print()
        print(f"üéØ Algorithme recommand√©: {rec.name}")
        print(f"üì¶ Classe scikit-learn: {rec.sklearn_class}")
        print()
        print(f"üìù Description:")
        print(f"   {rec.description}")
        print()
        
        if rec.parameters:
            print("‚öôÔ∏è  Param√®tres principaux:")
            for param, value in rec.parameters.items():
                print(f"   ‚Ä¢ {param}: {value}")
            print()
        
        if rec.notes:
            print("üí° Notes importantes:")
            for note in rec.notes:
                print(f"   ‚Ä¢ {note}")
        
        print()
        print("=" * 60)
        
        # Code exemple
        if rec.sklearn_class != "N/A":
            print()
            print("üìã Exemple de code:")
            print("-" * 60)
            print(f"from {rec.sklearn_class.rsplit('.', 1)[0]} import {rec.name.replace(' ', '')}")
            print()
            print(f"# Cr√©er le mod√®le")
            print(f"model = {rec.name.replace(' ', '')}()")
            print()
            print(f"# Entra√Æner")
            print(f"model.fit(X_train, y_train)")
            print()
            print(f"# Pr√©dire")
            print(f"predictions = model.predict(X_test)")
            print("-" * 60)
        
        print()


def main():
    """Fonction principale"""
    chooser = ScikitLearnChooser()
    
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                            ‚ïë
‚ïë      SCIKIT-LEARN ALGORITHM CHOOSER                       ‚ïë
‚ïë      Bas√© sur le flowchart officiel                       ‚ïë
‚ïë                                                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    while True:
        print("\nOptions:")
        print("  1. Mode interactif (recommand√©)")
        print("  2. Exemples pr√©d√©finis")
        print("  3. Quitter")
        print()
        
        choice = input("Votre choix (1-3): ").strip()
        
        if choice == "1":
            chooser.interactive_chooser()
            
        elif choice == "2":
            # Exemples
            print("\n" + "=" * 60)
            print("EXEMPLES")
            print("=" * 60)
            
            examples = [
                {
                    "name": "Classification de texte (spam)",
                    "params": {
                        "n_samples": 5000,
                        "task": "classification",
                        "has_labeled_data": True,
                        "predicting_category": True,
                        "text_data": True
                    }
                },
                {
                    "name": "Pr√©diction de prix immobiliers",
                    "params": {
                        "n_samples": 1500,
                        "task": "regression",
                        "has_labeled_data": True,
                        "predicting_quantity": True,
                        "n_features": 15
                    }
                },
                {
                    "name": "Segmentation de clients (clustering)",
                    "params": {
                        "n_samples": 8000,
                        "task": "clustering",
                        "has_labeled_data": False,
                        "need_structure": False
                    }
                },
                {
                    "name": "Classification d'images (grand dataset)",
                    "params": {
                        "n_samples": 150000,
                        "task": "classification",
                        "has_labeled_data": True,
                        "predicting_category": True,
                        "text_data": False
                    }
                }
            ]
            
            for i, example in enumerate(examples, 1):
                print(f"\n{i}. {example['name']}")
                rec = chooser.choose_algorithm(**example['params'])
                print(f"   ‚Üí {rec.name} ({rec.sklearn_class})")
            
            print()
            
        elif choice == "3":
            print("\nüëã Au revoir!")
            break
            
        else:
            print("‚ùå Choix invalide!")


if __name__ == "__main__":
    main()